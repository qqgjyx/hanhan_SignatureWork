import pandas as pd
from pathlib import Path

print(">>> running training_model_prep.py (v3: numeric coerce + safe pct_change)")

# ========== 1. è·¯å¾„é…ç½® ==========
BASE_DIR = Path("/Users/wyhmac/Desktop/SW")
STOCK_DIR = BASE_DIR / "åˆ°20251001"
MACRO_DIR = BASE_DIR / "macro_csv"
FED_DIR   = BASE_DIR / "ç¾è”å‚¨ä¿¡æ¯2"

stock_files = {
    "cd": STOCK_DIR / "cd100_20240630_20251001.xlsx",
    "energy": STOCK_DIR / "Energy100_20240630_20251001.xlsx",
    "financials": STOCK_DIR / "Financials100_20240630_20251001.xlsx",
    "industrials": STOCK_DIR / "Industrials100_20240630_20251001.xlsx",
    "it": STOCK_DIR / "IT100_20240630_20251001.xlsx",
}

gold_path = MACRO_DIR / "gold.csv"
oil_path  = MACRO_DIR / "oil.csv"
usd_path  = MACRO_DIR / "usd.csv"

fed_path  = FED_DIR / "fed_news_20240630_20251001_with_content.csv"

# ========== 2. è·¯å¾„æ£€æŸ¥ ==========
print("=== checking files ===")
to_check = list(stock_files.values()) + [gold_path, oil_path, usd_path, fed_path]
missing = []
for p in to_check:
    if p.exists():
        print("âœ… æ‰¾åˆ°äº†ï¼š", p)
    else:
        print("âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š", p)
        missing.append(str(p))
print("=== check done ===")

if missing:
    raise FileNotFoundError("ä¸‹é¢è¿™äº›æ–‡ä»¶æ²¡æ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥è·¯å¾„/æ–‡ä»¶åï¼š\n" + "\n".join(missing))

# ========== 3. è¾…åŠ©å‡½æ•° ==========
def cap_from_idx(idx: int) -> str:
    # 0-29 -> large, 30-64 -> mid, 65-99 -> small
    if idx < 30:
        return "large"
    elif idx < 30 + 35:
        return "mid"
    else:
        return "small"

# ========== 4. è¯»å–5ä¸ªexcel Ã— 100ä¸ªsheetï¼Œå±•å¼€ ==========
all_stocks = []

for sector, path in stock_files.items():
    xls = pd.ExcelFile(path)
    sheet_names = xls.sheet_names
    print(f"[{sector}] ä¸€å…± {len(sheet_names)} ä¸ªsheet")
    for i, sheet_name in enumerate(sheet_names):
        cap_bucket = cap_from_idx(i)
        ticker = sheet_name.strip()

        df = pd.read_excel(path, sheet_name=sheet_name)

        # ç»Ÿä¸€åˆ—å
        df = df.rename(columns={
            "Date": "date",
            "æœ€æ–°ä»·æ ¼": "close",
            "æˆäº¤é‡": "volume",
            "ç§»åŠ¨å¹³å‡ (15)": "ma15",
        })

        # è½¬æ—¥æœŸ
        df["date"] = pd.to_datetime(df["date"]).dt.date

        # ğŸ‘‡ å…³é”®ï¼šæŠŠæ•°å€¼åˆ—éƒ½å¼ºåˆ¶è½¬æˆæ•°å€¼ï¼Œè½¬ä¸äº†çš„å˜ NaN
        for col in ["close", "volume", "ma15"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")

        # è¡¥ä¸Šç»´åº¦
        df["ticker"] = ticker
        df["sector"] = sector
        df["cap_bucket"] = cap_bucket

        all_stocks.append(df)

stocks_df = pd.concat(all_stocks, ignore_index=True)
stocks_df = stocks_df.sort_values(["ticker", "date"]).reset_index(drop=True)

print("stocks_df shape:", stocks_df.shape)
print(stocks_df.head())

# ========== 5. å®è§‚åˆå¹¶ ==========
gold = pd.read_csv(gold_path)
oil  = pd.read_csv(oil_path)
usd  = pd.read_csv(usd_path)

for m in (gold, oil, usd):
    m["date"] = pd.to_datetime(m["date"]).dt.date

macro_df = (
    gold.rename(columns={"value": "gold_price"})
        .merge(oil.rename(columns={"value": "oil_price"}), on="date", how="outer")
        .merge(usd.rename(columns={"value": "usd_index"}), on="date", how="outer")
        .sort_values("date")
        .ffill()
)

print("macro_df range:", macro_df["date"].min(), "â†’", macro_df["date"].max())

# ========== 6. è¯»å–ç¾è”å‚¨æ–°é—»ï¼ˆpublished_utc ä¼˜å…ˆï¼‰ ==========
fed = pd.read_csv(fed_path)
fed_cols = list(fed.columns)
print("fed columns:", fed_cols)

# 6.1 æ‰¾æ—¥æœŸåˆ—ï¼Œä¼˜å…ˆ: published/publish/utc -> date -> time -> ç¬¬ä¸€åˆ—
date_col = None
for c in fed.columns:
    lc = c.lower()
    if "publish" in lc or "utc" in lc:
        date_col = c
        break
if date_col is None:
    for c in fed.columns:
        if "date" in c.lower():
            date_col = c
            break
if date_col is None:
    for c in fed.columns:
        if "time" in c.lower():
            date_col = c
            break
if date_col is None:
    date_col = fed.columns[0]

print("ä½¿ç”¨è¿™ä¸€åˆ—ä½œä¸ºæ—¥æœŸåˆ—:", date_col)

fed[date_col] = pd.to_datetime(fed[date_col], errors="coerce").dt.date
fed = fed.dropna(subset=[date_col])

# 6.2 æ‰¾å†…å®¹åˆ—
content_col = None
for c in fed.columns:
    if "content" in c.lower():
        content_col = c
        break
if content_col is None:
    for c in fed.columns:
        if "summary" in c.lower() or "text" in c.lower() or "body" in c.lower():
            content_col = c
            break
if content_col is None:
    content_col = fed.columns[-1]

print("ä½¿ç”¨è¿™ä¸€åˆ—ä½œä¸ºå†…å®¹åˆ—:", content_col)

fed_daily_text = (
    fed.groupby(date_col)[content_col]
       .apply(lambda x: "\n\n".join([str(t) for t in x if pd.notnull(t)]))
       .reset_index()
       .rename(columns={date_col: "date", content_col: "fed_text"})
)

print("fed_daily_text rows:", len(fed_daily_text))

# ========== 7. åˆå¹¶ï¼šè‚¡ç¥¨ + å®è§‚ + ç¾è”å‚¨ ==========
full = (
    stocks_df
    .merge(macro_df, on="date", how="left")
    .merge(fed_daily_text, on="date", how="left")
    .sort_values(["ticker", "date"])
    .reset_index(drop=True)
)

# å®è§‚ä» 2024-07-01 å¼€å§‹ï¼Œè£æ‰æ›´æ—©çš„
full = full[full["date"] >= pd.to_datetime("2024-07-01").date()].reset_index(drop=True)

# ğŸ‘‡ å†ä¿é™©ä¸€éï¼šåˆå¹¶åä¹ŸæŠŠ close/volume è½¬æˆæ•°å€¼
for col in ["close", "volume", "ma15", "gold_price", "oil_price", "usd_index"]:
    if col in full.columns:
        full[col] = pd.to_numeric(full[col], errors="coerce")

# ä¸¢æ‰æ²¡æœ‰ä»·æ ¼çš„è¡Œï¼ˆä¸èƒ½ç®—æ”¶ç›Šï¼‰
full = full.dropna(subset=["close"]).reset_index(drop=True)

# ========== 8. åšæ”¶ç›Š & å‰ç»æ”¶ç›Šï¼ˆå®‰å…¨ç‰ˆï¼‰ ==========
# pct_change è¿™é‡ŒæŒ‡å®š fill_method=Noneï¼Œå¯ä»¥å»æ‰é‚£ä¸ª FutureWarning
full["ret"] = (
    full.sort_values(["ticker", "date"])
        .groupby("ticker")["close"]
        .pct_change(fill_method=None)
)

HORIZON = 60
full["fwd_ret_60d"] = (
    full.sort_values(["ticker", "date"])
        .groupby("ticker")["close"]
        .shift(-HORIZON) / full["close"] - 1.0
)

print("final merged shape:", full.shape)
print(full.head(15))

# ========== 9. ä¿å­˜ ==========
out_path = BASE_DIR / "merged_panel_for_lstm.parquet"
full.to_parquet(out_path, index=False)
print("âœ… å·²ä¿å­˜åˆ°ï¼š", out_path)
